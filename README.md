# SHL Assessment Recommendation System

> âš ï¸ **Important Deployment Notice (Read First)**
>
> This is a **heavy RAG-based application** involving LLM inference + vector search. The **backend is deployed on Render (free tier ~512 MB RAM)** and the **frontend on Streamlit Cloud**. Due to limited memory and compute on free tiers, **responses may take several minutes or may feel slow/unresponsive**.
>
> This is a **deployment limitation, not a system design issue**.
>
> â€¢ The application runs **fast and smoothly on a local machine**.
> â€¢ There is **no free-tier hosting platform** that currently supports heavy RAG workloads efficiently.
> â€¢ To address this, a **working proof video** demonstrating real-time performance has been uploaded to the GitHub repository.

---

## Project Overview

This project implements an **intelligent SHL Assessment Recommendation System** that helps hiring managers and recruiters find the most relevant SHL assessments for a given **job description or natural language query**.

Instead of relying on keyword matching, the system understands **intent, skills, and role requirements**, then retrieves **semantically relevant assessments** while maintaining a **balanced mix of test types** (Knowledge, Ability, Personality, etc.).

The system is built using:

â€¢ **LLM-powered query understanding (Groq â€“ Llama 3.1 8B Instant)**
â€¢ **Pre-computed embeddings stored in FAISS** for fast similarity search
â€¢ **RAG-style retrieval pipeline** optimized for real-world recruiter queries

---

## Key Features

â€¢ Natural language job description understanding
â€¢ Semantic assessment retrieval using FAISS
â€¢ Intelligent skill extraction (hard + soft skills) via LLM
â€¢ Balanced recommendations across assessment types
â€¢ Precomputed embeddings for low-latency vector search
â€¢ End-to-end pipeline: Scraping â†’ Preprocessing â†’ Embedding â†’ Retrieval â†’ Evaluation
â€¢ Clean API-first backend with FastAPI
â€¢ Interactive Streamlit frontend for recruiters

---

## System Architecture

The system consists of **two independent components**:

### Backend (Deployed on Render)

â€¢ FastAPI-based REST service
â€¢ FAISS vector search engine
â€¢ Groq Llama 3.1 for query intent extraction
â€¢ Handles retrieval logic, scoring, and ranking

> Render was chosen over Vercel because **Vercel is not suitable for long-running RAG inference workloads**.

### Frontend (Deployed on Streamlit Cloud)

â€¢ Lightweight Streamlit UI
â€¢ Sends natural language queries to backend API
â€¢ Displays ranked assessment recommendations
â€¢ Highlights assessment type diversity

---

## System Block Diagram

> ðŸ“Š **Overall System Flow Diagram**

```
[PLACE BLOCK DIAGRAM IMAGE HERE]
```

This diagram should illustrate:
â€¢ URL scraping and data collection
â€¢ Preprocessing and embedding generation
â€¢ FAISS vector storage
â€¢ Query understanding via LLM
â€¢ Retrieval and ranking
â€¢ API â†’ Frontend interaction

---

## Working Prototype

### UI Screenshot

<img width="1919" height="925" alt="Working Proof Image" src="https://github.com/user-attachments/assets/f16302b1-7f50-4cb1-b44f-9916a5e0ae7a" />

### Working Proof Video

â€¢ Demonstrates real-time query â†’ recommendation flow
â€¢ Shows fast inference on local machine
â€¢ Confirms correct system behavior and output quality

Due to free-tier deployment limitations, a complete **working proof video** has been provided to demonstrate the systemâ€™s real-time performance and correctness.

â–¶ï¸ **Access Working Proof:**
[View Demo Video Folder](https://github.com/dushyant958/SHL-Assessment/tree/main/Working%20Proof)

This video confirms:

â€¢ Correct query understanding
â€¢ Relevant assessment recommendations
â€¢ Balanced test-type outputs

> The video serves as **performance and functionality proof**.

---

## Repository Structure

```
.
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py                # FastAPI backend for recommendation
â”‚   â”œâ”€â”€ retrieval_engine.py   # Core retrieval engine using Groq + FAISS
â”‚   â””â”€â”€ vector_store/
â”‚       â”œâ”€â”€ faiss_index.bin
â”‚       â”œâ”€â”€ faiss_index.py
â”‚       â”œâ”€â”€ embeddings.pkl
â”‚       â””â”€â”€ metadata.pkl
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ assessments.txt            # Raw scraped data from assessment detail pages
â”‚   â”œâ”€â”€ assessments_final.json     # Cleaned JSON converted from assessments.txt
â”‚   â”œâ”€â”€ processed_assessments.json # Preprocessed JSON for embedding
â”‚   â””â”€â”€ urls.json                  # URLs collected from SHL catalog pages
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ embeddings.py          # Script to generate embeddings (Gemini used previously)
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ evaluation.py          # Script for recall-based evaluation and re-ranking
â”‚   â”œâ”€â”€ SHL_submission.csv     # Final submission file provided to SHL
â”‚   â””â”€â”€ Gen_AI Dataset.csv     # Labeled ground-truth dataset used for evaluation
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                 # Streamlit frontend to query recommendations
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ collect_urls.py        # Script to collect assessment URLs (32 pages)
â”‚   â””â”€â”€ scrape_details.py      # Script to scrape assessment details from each URL
â”œâ”€â”€ preprocessing.py           # Preprocessing raw JSON into structured JSON
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Data Collection and Processing Pipeline

The data pipeline follows a **clear, multi-stage process**:

### 1. URL Collection

â€¢ SHL product catalog contains **32 pages** of Individual Test Solutions
â€¢ `scraper/collect_urls.py` scrapes all assessment URLs
â€¢ URLs are stored in `data/urls.json`

### 2. Assessment Data Scraping

â€¢ Each URL is visited using `scraper/scrape_details.py`
â€¢ Detailed assessment information is extracted
â€¢ Raw scraped output is stored in `data/assessments.txt`

### 3. JSON Conversion

â€¢ `assessments.txt` is converted into structured JSON
â€¢ Output saved as `data/assessments_final.json`

### 4. Preprocessing

â€¢ `preprocessing.py` cleans and normalizes data
â€¢ Generates canonical text representation for embeddings
â€¢ Output saved as `data/processed_assessments.json`

---

## Embeddings

â€¢ Generated using **Gemini Embedding Model** during data preparation
â€¢ Stored in **FAISS** inside the backend vector store
â€¢ Embedding dimensionality is fixed and consistent

> âš ï¸ Gemini embeddings are **not regenerated** during runtime due to API exhaustion.

> Only **query embeddings** are generated at inference time, ensuring dimensional compatibility.

---

## Retrieval Engine

Implemented in `api/retrieval_engine.py`:

â€¢ FAISS-based semantic retrieval
â€¢ LLM-driven query intent extraction using Groq Llama 3.1
â€¢ Skill identification:
â€¢ Hard skills
â€¢ Soft skills
â€¢ Intelligent ranking with test-type balancing

### Output Includes

â€¢ Assessment Name
â€¢ Assessment URL
â€¢ Test Type
â€¢ Similarity Score

---

## API

### Backend Framework

â€¢ FastAPI

### Endpoints

**Health Check**

```
GET /health
```

Returns

```
{"status": "ok"}
```

**Assessment Recommendation**

```
POST /recommend
```

Request Body

```
{
  "query": "Looking for a Java backend developer with strong communication skills"
}
```

Response

```
[
  {
    "assessment_name": "Adobe Photoshop CC",
    "assessment_url": "https://www.shl.com/...",
    "test_type": "K",
    "similarity_score": 0.87
  }
]
```

---

## Frontend

â€¢ Built with Streamlit
â€¢ Accepts free-form recruiter queries
â€¢ Displays ranked recommendations in tabular format
â€¢ Highlights assessment diversity

---

## Evaluation

â€¢ Implemented in `evaluation/evaluation.py`
â€¢ Uses **Gen_AI Dataset.csv** as ground-truth labels
â€¢ Dataset corresponds to the **official SHL submission format**

### Purpose

â€¢ Measure Recall@10
â€¢ Validate ranking quality
â€¢ Support re-ranking experimentation

Results saved to `SHL_submission.csv`.

---

## How to Run Locally

### Setup

```
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Run Backend

```
cd api
uvicorn app:app --reload
```

### Run Frontend

```
cd frontend
streamlit run app.py
```

---

## Final Notes

â€¢ This is a **production-style RAG system**, not a toy demo
â€¢ Free-tier cloud hosting is the primary performance bottleneck
â€¢ Local execution demonstrates intended speed and behavior
â€¢ Working proof video compensates for deployment constraints

---

## References

â€¢ SHL Product Catalog
â€¢ FAISS Vector Search
â€¢ Groq Llama 3.1

---
